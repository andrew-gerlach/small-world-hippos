{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_chp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qQzCA99sMryW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew-gerlach/small-world-hippos/blob/bf-small-world-hippos/load_chp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIvhc_R1D6k1"
      },
      "source": [
        "# Human Connectome Project (HCP) Dataset loader\n",
        "\n",
        "The HCP dataset comprises resting-state and task-based fMRI from a large sample of human subjects. The NMA-curated dataset includes time series data that has been preprocessed and spatially-downsampled by aggregating within 360 regions of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXIw61Dk-M5E"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCL-9lC2Kqst"
      },
      "source": [
        "# Necessary for visualization\n",
        "!pip install nilearn --quiet\n",
        "from nilearn import plotting, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eJOYQqgSMKV",
        "cellView": "form"
      },
      "source": [
        "#@title Figure settings\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSdEhS5jKzkb"
      },
      "source": [
        "# Basic parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL4crLoCzkzk"
      },
      "source": [
        "# The download cells will store the data in nested directories starting here:\n",
        "HCP_DIR = \"./hcp\"\n",
        "if not os.path.isdir(HCP_DIR):\n",
        "  os.mkdir(HCP_DIR)\n",
        "\n",
        "# The data shared for NMA projects is a subset of the full HCP dataset\n",
        "N_SUBJECTS = 339\n",
        "\n",
        "# The data have already been aggregated into ROIs from the Glasesr parcellation\n",
        "N_PARCELS = 360\n",
        "\n",
        "# The acquisition parameters for all tasks were identical\n",
        "TR = 0.72  # Time resolution, in sec\n",
        "\n",
        "# The parcels are matched across hemispheres with the same order\n",
        "HEMIS = [\"Right\", \"Left\"]\n",
        "\n",
        "# Each experiment was repeated multiple times in each subject\n",
        "N_RUNS_REST = 4\n",
        "N_RUNS_TASK = 2\n",
        "\n",
        "#NBACK number of frames per run\n",
        "FRAMES_PER_RUN = 405\n",
        "\n",
        "# Time series data are organized by experiment, with each experiment\n",
        "# having an LR and RL (phase-encode direction) acquistion\n",
        "BOLD_NAMES = [\n",
        "  \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\",\n",
        "  \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
        "  \"tfMRI_MOTOR_RL\", \"tfMRI_MOTOR_LR\",\n",
        "  \"tfMRI_WM_RL\", \"tfMRI_WM_LR\",\n",
        "  \"tfMRI_EMOTION_RL\", \"tfMRI_EMOTION_LR\",\n",
        "  \"tfMRI_GAMBLING_RL\", \"tfMRI_GAMBLING_LR\",\n",
        "  \"tfMRI_LANGUAGE_RL\", \"tfMRI_LANGUAGE_LR\",\n",
        "  \"tfMRI_RELATIONAL_RL\", \"tfMRI_RELATIONAL_LR\",\n",
        "  \"tfMRI_SOCIAL_RL\", \"tfMRI_SOCIAL_LR\"\n",
        "]\n",
        "\n",
        "# You may want to limit the subjects used during code development.\n",
        "# This will use all subjects:\n",
        "subjects = range(N_SUBJECTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErP_ocaxK9FU"
      },
      "source": [
        "# Downloading data\n",
        "\n",
        "The rest and task data are shared in different files, but they will unpack into the same directory structure.\n",
        "\n",
        "Each file is fairly large and will take some time to download. If you are focusing only on rest or task analyses, you may not want to download only that dataset.\n",
        "\n",
        "We also separately provide some potentially useful behavioral covariate information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lh1SEyZ_Kdh"
      },
      "source": [
        "fname = \"hcp_rest.tgz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/bqp7m/download/\n",
        "  !tar -xzf $fname -C $HCP_DIR --strip-components=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ubuyGN7siwI"
      },
      "source": [
        "fname = \"hcp_task.tgz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/s4h8j/download/\n",
        "  !tar -xzf $fname -C $HCP_DIR --strip-components=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4EQ0Y--VqUg"
      },
      "source": [
        "fname = \"hcp_covariates.tgz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/x5p4g/download/\n",
        "  !tar -xzf $fname -C $HCP_DIR --strip-components=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLWaBeoJM28-"
      },
      "source": [
        "fname = f\"{HCP_DIR}/atlas.npz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/j5kuc/download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaF8v-UBTcxq"
      },
      "source": [
        "## Loading region information\n",
        "\n",
        "Downloading either dataset will create the `regions.npy` file, which contains the region name and network assignment for each parcel.\n",
        "\n",
        "Detailed information about the name used for each region is provided [in the Supplement](https://static-content.springer.com/esm/art%3A10.1038%2Fnature18933/MediaObjects/41586_2016_BFnature18933_MOESM330_ESM.pdf) to [Glasser et al. 2016](https://www.nature.com/articles/nature18933).\n",
        "\n",
        "Information about the network parcellation is provided in [Ji et al, 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6289683/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28q_GDlXOyMi"
      },
      "source": [
        "regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
        "region_info = dict(\n",
        "    name=regions[0].tolist(),\n",
        "    network=regions[1],\n",
        "    myelin=regions[2].astype(np.float),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5_wD8BMbSwz"
      },
      "source": [
        "# Load github directory for access to Glasser atlas file\n",
        "!git clone https://github.com/andrew-gerlach/small-world-hippos.git\n",
        "# Load Glasser atlas\n",
        "glasser_atlas = nib.load('small-world-hippos/MMP_in_MNI_corr.nii')\n",
        "img = glasser_atlas.get_fdata()\n",
        "# Renumber to be continuous from 1 to 360 (right is 1-180, left is 201-380 in original atlas)\n",
        "for i in range(201,381):\n",
        "  img[img == i] = i-20\n",
        "  \n",
        "# Initialize storage for list of nodes in each network\n",
        "unique_networks = np.unique(region_info['network'])\n",
        "nNet = len(unique_networks)          # number of networks\n",
        "network_regions = {}                 # initialize\n",
        "for net in unique_networks:\n",
        "  network_regions[net] = []\n",
        "\n",
        "# Populate lists and extract node volume\n",
        "nodeVol = np.zeros(N_PARCELS)\n",
        "for i in range(N_PARCELS):\n",
        "  nodeVol[i] = np.sum(img == (i+1))\n",
        "  network_regions[region_info['network'][i]].append(region_info['name'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUmm7gjhNBVF"
      },
      "source": [
        "We also provide the [parcellation on the fsaverage5 surface](https://figshare.com/articles/HCP-MMP1_0_projected_on_fsaverage/3498446) and approximate MNI coordinates of each region, which can be useful for visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJTGGZDHNSBD"
      },
      "source": [
        "with np.load(f\"{HCP_DIR}/atlas.npz\") as dobj:\n",
        "  atlas = dict(**dobj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYDxvWrbIxxk"
      },
      "source": [
        "# Helper functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDFPnQ07MmEd"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnq7H5h_IxLi"
      },
      "source": [
        "def get_image_ids(name):\n",
        "  \"\"\"Get the 1-based image indices for runs in a given experiment.\n",
        "\n",
        "    Args:\n",
        "      name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    Returns:\n",
        "      run_ids (list of int) : Numeric ID for experiment image files\n",
        "\n",
        "  \"\"\"\n",
        "  run_ids = [\n",
        "    i for i, code in enumerate(BOLD_NAMES, 1) if name.upper() in code\n",
        "  ]\n",
        "  if not run_ids:\n",
        "    raise ValueError(f\"Found no data for '{name}''\")\n",
        "  return run_ids\n",
        "\n",
        "def load_timeseries(subject, name, runs=None, concat=True, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject.\n",
        "  \n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    run (None or int or list of ints): 0-based run(s) of the task to load,\n",
        "      or None to load all runs.\n",
        "    concat (bool) : If True, concatenate multiple runs in time\n",
        "    remove_mean (bool) : If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_tp array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  # Get the list relative 0-based index of runs to use\n",
        "  if runs is None:\n",
        "    runs = range(N_RUNS_REST) if name == \"rest\" else range(N_RUNS_TASK)\n",
        "  elif isinstance(runs, int):\n",
        "    runs = [runs]\n",
        "\n",
        "  # Get the first (1-based) run id for this experiment \n",
        "  offset = get_image_ids(name)[0]\n",
        "\n",
        "  # Load each run's data\n",
        "  bold_data = [\n",
        "      load_single_timeseries(subject, offset + run, remove_mean) for run in runs\n",
        "  ]\n",
        "\n",
        "  # Optionally concatenate in time\n",
        "  if concat:\n",
        "    bold_data = np.concatenate(bold_data, axis=-1)\n",
        "\n",
        "  return bold_data\n",
        "\n",
        "\n",
        "def load_single_timeseries(subject, bold_run, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject and single run.\n",
        "  \n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    bold_run (int): 1-based run index, across all tasks\n",
        "    remove_mean (bool): If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  bold_path = f\"{HCP_DIR}/subjects/{subject}/timeseries\"\n",
        "  bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
        "  ts = np.load(f\"{bold_path}/{bold_file}\")\n",
        "  if remove_mean:\n",
        "    ts -= ts.mean(axis=1, keepdims=True)\n",
        "  return ts\n",
        "\n",
        "def load_evs(subject, name, condition):\n",
        "  \"\"\"Load EV (explanatory variable) data for one task condition.\n",
        "\n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of task\n",
        "    condition (str) : Name of condition\n",
        "\n",
        "  Returns\n",
        "    evs (list of dicts): A dictionary with the onset, duration, and amplitude\n",
        "      of the condition for each run.\n",
        "\n",
        "  \"\"\"\n",
        "  evs = []\n",
        "  for id in get_image_ids(name):\n",
        "    task_key = BOLD_NAMES[id - 1]\n",
        "    ev_file = f\"{HCP_DIR}/subjects/{subject}/EVs/{task_key}/{condition}.txt\"\n",
        "    ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
        "    ev = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
        "    evs.append(ev)\n",
        "  return evs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQzCA99sMryW"
      },
      "source": [
        "## Task-based analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgnEuN0gMqxP"
      },
      "source": [
        "def condition_frames(run_evs, skip=0):\n",
        "  \"\"\"Identify timepoints corresponding to a given condition in each run.\n",
        "\n",
        "  Args:\n",
        "    run_evs (list of dicts) : Onset and duration of the event, per run\n",
        "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
        "      for hemodynamic lag\n",
        "\n",
        "  Returns:\n",
        "    frames_list (list of 1D arrays): Flat arrays of frame indices, per run\n",
        "\n",
        "  \"\"\"\n",
        "  frames_list = []\n",
        "  for ev in run_evs:\n",
        "\n",
        "    # Determine when trial starts, rounded down\n",
        "    start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
        "\n",
        "    # Use trial duration to determine how many frames to include for trial\n",
        "    duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
        "\n",
        "    # Take the range of frames that correspond to this specific trial\n",
        "    frames = [s + np.arange(skip, d) for s, d in zip(start, duration)]\n",
        "\n",
        "    frames_list.append(np.concatenate(frames))\n",
        "\n",
        "  return frames_list\n",
        "\n",
        "\n",
        "def selective_average(timeseries_data, ev, skip=0):\n",
        "  \"\"\"Take the temporal mean across frames for a given condition.\n",
        "\n",
        "  Args:\n",
        "    timeseries_data (array or list of arrays): n_parcel x n_tp arrays\n",
        "    ev (dict or list of dicts): Condition timing information\n",
        "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
        "      for hemodynamic lag\n",
        "\n",
        "  Returns:\n",
        "    avg_data (1D array): Data averagted across selected image frames based\n",
        "    on condition timing\n",
        "\n",
        "  \"\"\"\n",
        "  # Ensure that we have lists of the same length\n",
        "  if not isinstance(timeseries_data, list):\n",
        "    timeseries_data = [timeseries_data]\n",
        "  if not isinstance(ev, list):\n",
        "    ev = [ev]\n",
        "  if len(timeseries_data) != len(ev):\n",
        "    raise ValueError(\"Length of `timeseries_data` and `ev` must match.\")\n",
        "\n",
        "  # Identify the indices of relevant frames\n",
        "  frames = condition_frames(ev, skip)\n",
        "\n",
        "  # Select the frames from each image\n",
        "  selected_data = []\n",
        "  for run_data, run_frames in zip(timeseries_data, frames):\n",
        "    run_frames = run_frames[run_frames < run_data.shape[1]]\n",
        "    selected_data.append(run_data[:, run_frames])\n",
        "\n",
        "  # Take the average in each parcel\n",
        "  avg_data = np.concatenate(selected_data, axis=-1).mean(axis=-1)\n",
        "\n",
        "  return avg_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m29ahkxHHwP"
      },
      "source": [
        "# Resting-state analyses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyprnpLjB-zX"
      },
      "source": [
        "Load a single run of resting-state data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNvXQ6JuK6HY"
      },
      "source": [
        "help(load_timeseries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBrDMr59CAqi"
      },
      "source": [
        "timeseries = load_timeseries(subject=0, name=\"rest\", runs=1)\n",
        "print(timeseries.shape)  # n_parcel x n_timepoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-umDZqB0MqFe"
      },
      "source": [
        "Load a concatenated resting-state timeseries (using all runs' data) for each subject:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFD8UcUOLZtk"
      },
      "source": [
        "timeseries_rest = []\n",
        "for subject in subjects:\n",
        "  ts_concat = load_timeseries(subject, \"rest\")\n",
        "  timeseries_rest.append(ts_concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6XQc4JDOlEA"
      },
      "source": [
        "## Run a simple correlation-based \"functional connectivity\" analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpQgzqh4MuoL"
      },
      "source": [
        "Generate a correlation matrix (showing \"functional connectivity\" or FC) for each subject and plot the group average:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oHPBwcxznLb"
      },
      "source": [
        "fc = np.zeros((N_SUBJECTS, N_PARCELS, N_PARCELS))\n",
        "for sub, ts in enumerate(timeseries_rest):\n",
        "  fc[sub] = np.corrcoef(ts)\n",
        "\n",
        "group_fc = fc.mean(axis=0)\n",
        "\n",
        "plt.imshow(group_fc, interpolation=\"none\", cmap=\"bwr\", vmin=-1, vmax=1)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qETTLTXVM73c"
      },
      "source": [
        "Plot the profile of FC values between a particular \"seed\" parcel and every parcel in the dataset, separated by hemisphere:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elcKmhupnD4-"
      },
      "source": [
        "seed_roi = \"R_9-46d\"  # name of seed parcel\n",
        "seed_idx = region_info[\"name\"].index(seed_roi)\n",
        "\n",
        "hemi_fc = np.split(group_fc, 2)\n",
        "\n",
        "# Plot the FC profile across the right and left hemisphere target regions\n",
        "for i, hemi_fc in enumerate(hemi_fc):\n",
        "  plt.plot(hemi_fc[:, seed_idx], label=f\"{HEMIS[i]} hemisphere\")\n",
        "plt.title(f\"FC for region {seed_roi}\")\n",
        "plt.xlabel(\"Target region\")\n",
        "plt.ylabel(\"Correlation (FC)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUBV9CGLNkZ9"
      },
      "source": [
        "Threshold the correlation matrix to produce a connectome, and plot it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4d_qhh1Npd-"
      },
      "source": [
        "plotting.view_connectome(group_fc, atlas[\"coords\"], edge_threshold=\"99%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03UvWa67EM7n"
      },
      "source": [
        "ACTUAL PROJECT WORK\n",
        "Calculate the node-wise functional connectivity summary features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmNoP8PrEKmy"
      },
      "source": [
        "# Node-to-node connectivity\n",
        "def extract_connectivities(seed_rois, target_rois, fc, nSubj):\n",
        "  fc_summary = np.zeros((N_SUBJECTS,len(seed_rois),len(target_rois)))\n",
        "  for i_seed in range(len(seed_rois)):\n",
        "    seed_idx = region_info[\"name\"].index(seed_rois[i_seed])\n",
        "    for i_target in range(len(target_rois)):\n",
        "      target_idx = region_info[\"name\"].index(target_rois[i_target])\n",
        "      if target_idx == seed_idx:\n",
        "        continue \n",
        "      for i_subj in range(nSubj):\n",
        "        fc_summary[i_subj,i_seed,i_target] = fc[i_subj,seed_idx,target_idx]\n",
        "\n",
        "  return fc_summary\n",
        "\n",
        "# example to calculate right dlPFC to DAN\n",
        "seed_rois = [\"R_9-46d\"]\n",
        "target_rois = network_regions['Dorsal-atten']\n",
        "fc_n2n = extract_connectivities(seed_rois, target_rois, fc, N_SUBJECTS)\n",
        "fc_dlPFC_to_DAN = fc_n2n.mean(axis=2)    # average over all target nodes\n",
        "fc_dlPFC_to_DAN[0:10]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKOzUn2iPnQL"
      },
      "source": [
        "# Task analyses\n",
        "\n",
        "Description of each task, task timing, and conditions is located [here](https://protocols.humanconnectome.org/HCP/3T/task-fMRI-protocol-details.html).\n",
        "\n",
        "These are the condition names for each task:\n",
        "\n",
        "```\n",
        "- MOTOR: cue, lf, lh, rf, rh, t\n",
        "- WM:\n",
        "    0bk_body, 0bk_faces, 0bk_nir, 0bk_placed, 0bk_tools, \n",
        "    2bk_body, 2bk_faces, 2bk_nir, 2bk_placed, 2bk_tools,\n",
        "    0bk_cor, 0bk_err,\n",
        "    2bk_cor, 2bk_err,\n",
        "    all_bk_cor, all_bk_err\n",
        "- EMOTION: feat, neutral\n",
        "- GAMBLING: loss, loss_event, win, win_event, neut_event\n",
        "- LANGUAGE:\n",
        "    cue,\n",
        "    math, story\n",
        "    present_math, present_story,\n",
        "    question_math, question_story,\n",
        "    response_math, response_story\n",
        "- RELATIONAL: error, match, relation\n",
        "- SOCIAL: mental_resp, mental, other_resp, rnd\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlFhngy2UkTq"
      },
      "source": [
        "## Load individual runs for a given task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6_wbj3tM4wE"
      },
      "source": [
        "print(os.listdir(f\"{HCP_DIR}/subjects/128/EVs/tfMRI_WM_RL/\"))\n",
        "!cat ./hcp/subjects/128/EVs/tfMRI_WM_RL/2bk_body.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-oxgXHKn8v4"
      },
      "source": [
        "Load working memory data for each subject"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaYkLCfcn8Oq"
      },
      "source": [
        "task = \"wm\"\n",
        "\n",
        "conditions_2back = [\"2bk_body\", \"2bk_faces\", \"2bk_places\", \"2bk_tools\"] \n",
        "N_CONDS = len(conditions_2back)\n",
        "\n",
        "BLOCK_FRAMES = int(27.5/TR) # 27.5s is the duration of each block\n",
        "\n",
        "subjects = [0, 212, 169] # Use for debugging\n",
        "\n",
        "timeseries_task_wm_2back = []\n",
        "\n",
        "for k, subject in enumerate(subjects):\n",
        "\n",
        "  # Load full timeseries\n",
        "  timeseries = load_timeseries(subject=subject, name=task) # this is a 360, 810 numpy.ndarray\n",
        "  # Extract 2back timepoints \n",
        "  evs = [load_evs(subject, task, cond) for cond in conditions_2back]\n",
        "  ## Notes: evs is a list of 4 (sub)lists - 1 per condition\n",
        "  # Each sublist contains 2 dictionaries - 1 per run\n",
        "  # Each dictionary contains onset, duration, and amplitude keys\n",
        "  # To Do: extract onset values from each dictionary\n",
        "\n",
        "  ts_2bk = np.zeros((N_PARCELS, N_CONDS*N_RUNS_TASK*BLOCK_FRAMES))\n",
        "  for i in range(N_CONDS):\n",
        "    for j in range(N_RUNS_TASK):\n",
        "      onset_frames = int(evs[i][j][\"onset\"]/TR) + j*FRAMES_PER_RUN\n",
        "      ts_2bk[:,(i*N_RUNS_TASK+j)*BLOCK_FRAMES:(i*N_RUNS_TASK+j + 1)*BLOCK_FRAMES] = timeseries[:,onset_frames:onset_frames+BLOCK_FRAMES]\n",
        "\n",
        "  # Concat new timeseries into timeseries_task_wm_2back\n",
        "\n",
        "  timeseries_task_wm_2back.append(ts_2bk)\n",
        "\n",
        "\n",
        "print(timeseries_task_wm_2back)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zglt0E9_VtO5"
      },
      "source": [
        "Load each subject's data for a specific task, separately for each run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MObaV3AT043I"
      },
      "source": [
        "timeseries_task = []\n",
        "for subject in subjects:\n",
        "  timeseries_task.append(load_timeseries(subject, \"motor\", concat=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljvZektJ_Qny"
      },
      "source": [
        "## Run a simple subtraction analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt8x-b68NB8W"
      },
      "source": [
        "help(load_evs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FZtcNLZNDBJ"
      },
      "source": [
        "help(selective_average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDnGGT7HPR2Y"
      },
      "source": [
        "task = \"motor\"\n",
        "conditions = [\"lf\", \"rf\"]  # Run a substraction analysis between two conditions\n",
        "\n",
        "contrast = []\n",
        "for subject in subjects:\n",
        "\n",
        "  # Get the average signal in each region for each condition\n",
        "  evs = [load_evs(subject, task, cond) for cond in conditions]\n",
        "  avgs = [selective_average(timeseries_task[subject], ev) for ev in evs]\n",
        "\n",
        "  # Store the region-wise difference\n",
        "  contrast.append(avgs[0] - avgs[1])\n",
        "\n",
        "group_contrast = np.mean(contrast, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul75yDmvZ2Lb"
      },
      "source": [
        "Plot group-averaged contrast value across regions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuDVBClQzg9G"
      },
      "source": [
        "hemi_contrasts = np.split(group_contrast, 2)\n",
        "\n",
        "for i, hemi_contrast in enumerate(hemi_contrasts):\n",
        "  plt.plot(hemi_contrast, label=f\"{HEMIS[i]} hemisphere\")\n",
        "\n",
        "plt.title(\"Contrast of %s - %s\" % (conditions[0], conditions[1]))\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel('Contrast')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwYfUtzpOCYv"
      },
      "source": [
        "Plot the regional values on the surface of one hemisphere:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWk4BOcoOFoL"
      },
      "source": [
        "fsaverage = datasets.fetch_surf_fsaverage()\n",
        "surf_contrast = group_contrast[atlas[\"labels_L\"]]\n",
        "plotting.view_surf(fsaverage['infl_left'],\n",
        "                   surf_contrast,\n",
        "                   vmax=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrQBIhx_B3d6"
      },
      "source": [
        "## Characterize values by functional network\n",
        "\n",
        "Average the contrast values within parcels belonging to each network and plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rwDIKDPzrm_"
      },
      "source": [
        "# Get unique network labels\n",
        "network_names = np.unique(region_info[\"network\"])\n",
        "\n",
        "hemi_networks = np.split(region_info[\"network\"], 2)\n",
        "hemi_contrasts = np.split(group_contrast, 2)\n",
        "\n",
        "# Get and plot mean contrast value per network, by hemisphere\n",
        "for hemi, hemi_network, hemi_contrast in zip(HEMIS, hemi_networks, hemi_contrasts):\n",
        "  network_vals = []\n",
        "  for network in network_names:\n",
        "    network_vals.append(hemi_contrast[hemi_network == network].mean())\n",
        "  plt.barh(network_names, network_vals, alpha=.5, label=f\"{hemi} hemi\")\n",
        "\n",
        "plt.axvline(0)\n",
        "plt.xlabel(\"Amplitude difference\")\n",
        "plt.title(f\"Contrast of {conditions[0]} - {conditions[1]}\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmxNKtGFxmgx"
      },
      "source": [
        "# Behavioral covariates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgnYw0oxYOtB"
      },
      "source": [
        "## Task performance measures\n",
        "\n",
        "The dataset also includes aggregate behavior for each task run stored in task-specific `.csv` files. It is possible to load and work with these files using `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFSLnzzV49u"
      },
      "source": [
        "import pandas as  pd\n",
        "\n",
        "wm_behavior = np.genfromtxt(\"hcp/behavior/wm.csv\",\n",
        "                            delimiter=\",\",\n",
        "                            names=True,\n",
        "                            dtype=None,\n",
        "                            encoding=\"utf\")\n",
        "#print(wm_behavior[:5])\n",
        "#print(wm_behavior.dtype.names)\n",
        "\n",
        "# Make separate dataframes for 0 and 2 back performance measures\n",
        "back0_array = (wm_behavior[np.where((wm_behavior[\"ConditionName\"] == \"0BK_BODY\") | (wm_behavior[\"ConditionName\"] == \"0BK_FACE\") | (wm_behavior[\"ConditionName\"] == \"0BK_TOOL\") | (wm_behavior[\"ConditionName\"] == \"0BK_PLACE\"))])\n",
        "back2_array = (wm_behavior[np.where((wm_behavior[\"ConditionName\"] == \"2BK_BODY\") | (wm_behavior[\"ConditionName\"] == \"2BK_FACE\") | (wm_behavior[\"ConditionName\"] == \"2BK_TOOL\") | (wm_behavior[\"ConditionName\"] == \"2BK_PLACE\"))])\n",
        "back0_df = pd.DataFrame(back0_array)\n",
        "back2_df = pd.DataFrame(back2_array)\n",
        "\n",
        "# Make dataframes with 1 performance score per subject (averaged across runs)\n",
        "back0_mean = back0_df.groupby('Subject').mean()\n",
        "back2_mean = back2_df.groupby('Subject').mean()\n",
        "\n",
        "# Concat 0 and 2 back dataframes\n",
        "wm_behavior_byBlock = pd.concat([back0_mean, back2_mean], keys=['0back', '2back'])\n",
        "\n",
        "# Average by subject and run\n",
        "#back0_df.groupby(['Subject', 'Run']).mean()\n",
        "#back2_df.groupby(['Subject', 'Run']).mean()\n",
        "\n",
        "# Accuracy Mean and standard deviation \n",
        "print(\"0 back Accuracy; mean SD\")\n",
        "print(round(back0_mean[\"ACC\"].mean(), 2), round(back0_mean[\"ACC\"].std(),2 ))\n",
        "print(\"2 back Accuracy; mean SD\")\n",
        "print(round(back2_mean[\"ACC\"].mean(),2), round(back2_mean[\"ACC\"].std(),2))\n",
        "\n",
        "# RT Mean and standard deviation \n",
        "print(\"0 back MEDIAN_RT; mean SD\")\n",
        "print(round(back0_mean[\"MEDIAN_RT\"].mean(), 2), round(back0_mean[\"MEDIAN_RT\"].std(),2 ))\n",
        "print(\"2 back MEDIAN_RT; mean SD\")\n",
        "print(round(back2_mean[\"MEDIAN_RT\"].mean(), 2), round(back2_mean[\"MEDIAN_RT\"].std(),2 ))\n",
        "\n",
        "# Histograms\n",
        "#back0_mean.hist(bins=20)\n",
        "#back2_mean.hist(bins=20)\n",
        "hist_acc_0 = back0_mean[\"ACC\"].hist(bins=20, color = \"blue\", alpha=0.3)\n",
        "hist_acc_2 = back2_mean[\"ACC\"].hist(bins=20, color = \"red\", alpha=0.3)\n",
        "\n",
        "hist_rt_0 = back0_mean[\"MEDIAN_RT\"].hist(bins=20, color = \"green\", alpha=0.3)\n",
        "hist_rt_2 = back2_mean[\"MEDIAN_RT\"].hist(bins=20, color = \"yellow\", alpha=0.3)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cHs2w31WHl1"
      },
      "source": [
        "But, while not formally taught as part of the course, [`pandas`](https://pandas.pydata.org/) offers more powerful tools for tabular data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6UJ63g9WqFH"
      },
      "source": [
        "## Pseudo-demographics\n",
        "\n",
        "The NMA-distributed version of the HCP data does not contain any real demographic information. But we have created a synthetic dataset of 25 \"demographic\" variables based on a model trained on the original dataset to predict demographics from resting-state network organization measures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEbatTiEWvtC"
      },
      "source": [
        "demo = np.load(\"hcp/pseudo_demographics.npy\")\n",
        "demo.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HCgSp9nXB7r"
      },
      "source": [
        "## Original subject IDs\n",
        "\n",
        "The dataset also contains a key to map the ordinal subject numbers to the IDs used in the original HCP dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsd1CjXAXLB5"
      },
      "source": [
        "ids = np.loadtxt(\"hcp/orig_ids.txt\")\n",
        "print(ids[:8])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}